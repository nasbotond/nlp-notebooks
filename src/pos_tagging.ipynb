{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mufXIP9MxhHp"
      },
      "source": [
        "# POS-tagging with a classical sequence tagging model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hlrpStixpuX"
      },
      "source": [
        "Import necessary modules. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stretch-occasions",
        "outputId": "59a78456-f87e-4abe-e423-90e41ff8f82c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn<0.24\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.21.6)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.2\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.14\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 68.3 MB/s \n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.9\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 70.0 MB/s \n",
            "\u001b[?25hCollecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.8)\n",
            "Collecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 6.0.0\n",
            "    Uninstalling smart-open-6.0.0:\n",
            "      Successfully uninstalled smart-open-6.0.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed catalogue-2.0.7 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 smart-open-5.2.1 spacy-3.3.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.15 typer-0.4.1 typing-extensions-3.10.0.2\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.10.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.15)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install -U 'scikit-learn<0.24'\n",
        "!pip install -U spacy\n",
        "\n",
        "from typing import List, Dict, Union\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "\n",
        "! python3 -m spacy download en\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "banner-flexibility"
      },
      "source": [
        "## Corpus visualization: NLTK Brown corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldlsg5naNbEy",
        "outputId": "9ad06564-b17b-45d3-bd9d-6499a62006b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEGFKIlCNhjt",
        "outputId": "7e7373ca-3ec0-4da8-dd7b-8584abd0b6a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n",
            "[('It', 'PRON'), ('urged', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('city', 'NOUN'), ('``', '.'), ('take', 'VERB'), ('steps', 'NOUN'), ('to', 'PRT'), ('remedy', 'VERB'), (\"''\", '.'), ('this', 'DET'), ('problem', 'NOUN'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "brown: nltk.corpus.util.LazyCorpusLoader\n",
        "print(brown.words())\n",
        "\n",
        "sents = brown.tagged_sents(tagset='universal')\n",
        "print(sents[10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mH0DUIGuG-R"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "za3Ke4sYosIs"
      },
      "outputs": [],
      "source": [
        "def word2features(sent: spacy.tokens.Doc, i: int) -> Dict[str, Union[str, bool]]:\n",
        "    features: Dict[str, Union[str, bool]] = {}\n",
        "\n",
        "    bos = sent[i].is_sent_start\n",
        "    eos = sent[i].is_sent_end\n",
        "    word = sent[i].text\n",
        "    leng = len(sent)\n",
        "    \n",
        "    features = {\n",
        "        \"word.lower()\": word.lower(),\n",
        "        \"word[-3:]\": word[-3:].lower(),\n",
        "        \"word[-2:]\": word[-3:].lower(),\n",
        "        \"word.isupper()\": word.isupper(),\n",
        "        \"word.istitle()\": word.istitle(),\n",
        "        \"word.isdigit()\": word.isdigit()\n",
        "    }\n",
        "    \n",
        "    if bos and leng>1:\n",
        "        a_word = sent[i+1].text\n",
        "        features.update({\"+1:word.lower()\": a_word.lower(),\n",
        "                        \"+1:word.istitle()\": a_word.istitle(),\n",
        "                        \"+1:word.isupper()\": a_word.isupper(),\n",
        "                        \"BOS\": True})\n",
        "        \n",
        "    elif eos and leng>1:\n",
        "        b_word = sent[i-1].text\n",
        "        features.update({\"-1:word.lower()\": b_word.lower(),\n",
        "                        \"-1:word.istitle()\": b_word.istitle(),\n",
        "                        \"-1:word.isupper()\": b_word.isupper(),\n",
        "                        \"EOS\": True})\n",
        "        \n",
        "    elif (eos or bos) and leng<=1:\n",
        "        features.update({\"BOS\": True,\n",
        "                        \"EOS\": True})\n",
        "        \n",
        "    else:\n",
        "        b_word = sent[i-1].text\n",
        "        a_word = sent[i+1].text\n",
        "        features.update({\"-1:word.lower()\": b_word.lower(),\n",
        "                        \"-1:word.istitle()\": b_word.istitle(),\n",
        "                        \"-1:word.istitle()\": b_word.istitle(),\n",
        "                        \"+1:word.lower()\": a_word.lower(),\n",
        "                        \"+1:word.istitle()\": a_word.istitle(),\n",
        "                        \"+1:word.isupper()\": a_word.isupper()})           \n",
        "    \n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z4sS6c05AfsW"
      },
      "outputs": [],
      "source": [
        "def sent2features(sent: spacy.tokens.Doc) -> List[Dict[str, Union[str, bool]]]:\n",
        "    features_list: List[Dict[str, Union[str, bool]]] = []\n",
        "\n",
        "    for i in range(0, len(sent)):\n",
        "        features_list.append(word2features(sent, i))\n",
        "\n",
        "    return features_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4NJLmYnFKzb",
        "outputId": "c4225940-baac-43f1-b321-94d415d839a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'+1:word.istitle()': False,\n",
              "  '+1:word.isupper()': False,\n",
              "  '+1:word.lower()': 'is',\n",
              "  'BOS': True,\n",
              "  'word.isdigit()': False,\n",
              "  'word.istitle()': False,\n",
              "  'word.isupper()': False,\n",
              "  'word.lower()': 'this',\n",
              "  'word[-2:]': 'his',\n",
              "  'word[-3:]': 'his'},\n",
              " {'+1:word.istitle()': True,\n",
              "  '+1:word.isupper()': True,\n",
              "  '+1:word.lower()': 'a',\n",
              "  '-1:word.istitle()': False,\n",
              "  '-1:word.lower()': 'this',\n",
              "  'word.isdigit()': False,\n",
              "  'word.istitle()': False,\n",
              "  'word.isupper()': False,\n",
              "  'word.lower()': 'is',\n",
              "  'word[-2:]': 'is',\n",
              "  'word[-3:]': 'is'},\n",
              " {'+1:word.istitle()': False,\n",
              "  '+1:word.isupper()': False,\n",
              "  '+1:word.lower()': '1',\n",
              "  '-1:word.istitle()': False,\n",
              "  '-1:word.lower()': 'is',\n",
              "  'word.isdigit()': False,\n",
              "  'word.istitle()': True,\n",
              "  'word.isupper()': True,\n",
              "  'word.lower()': 'a',\n",
              "  'word[-2:]': 'a',\n",
              "  'word[-3:]': 'a'},\n",
              " {'+1:word.istitle()': False,\n",
              "  '+1:word.isupper()': False,\n",
              "  '+1:word.lower()': 'sentence',\n",
              "  '-1:word.istitle()': True,\n",
              "  '-1:word.lower()': 'a',\n",
              "  'word.isdigit()': True,\n",
              "  'word.istitle()': False,\n",
              "  'word.isupper()': False,\n",
              "  'word.lower()': '1',\n",
              "  'word[-2:]': '1',\n",
              "  'word[-3:]': '1'},\n",
              " {'+1:word.istitle()': False,\n",
              "  '+1:word.isupper()': False,\n",
              "  '+1:word.lower()': '.',\n",
              "  '-1:word.istitle()': False,\n",
              "  '-1:word.lower()': '1',\n",
              "  'word.isdigit()': False,\n",
              "  'word.istitle()': False,\n",
              "  'word.isupper()': False,\n",
              "  'word.lower()': 'sentence',\n",
              "  'word[-2:]': 'nce',\n",
              "  'word[-3:]': 'nce'},\n",
              " {'-1:word.istitle()': False,\n",
              "  '-1:word.isupper()': False,\n",
              "  '-1:word.lower()': 'sentence',\n",
              "  'EOS': True,\n",
              "  'word.isdigit()': False,\n",
              "  'word.istitle()': False,\n",
              "  'word.isupper()': False,\n",
              "  'word.lower()': '.',\n",
              "  'word[-2:]': '.',\n",
              "  'word[-3:]': '.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from spacy.tokens import Doc\n",
        "words = ['this', 'is', 'A', '1', 'sentence', '.']\n",
        "spaces = [True, True, True, True, False, False]\n",
        "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
        "\n",
        "sent2features(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "thWHu_hc0gIb"
      },
      "outputs": [],
      "source": [
        "x: List[List[Dict[str, Union[str, bool]]]] = []\n",
        "y: List[List[str]] = []\n",
        "\n",
        "for sent in sents:\n",
        "    words = []\n",
        "    pos = []\n",
        "    spaces = []\n",
        "    for word in sent:\n",
        "        words.append(word[0])\n",
        "        pos.append(word[1])\n",
        "        if word[1] == '.':\n",
        "            spaces.append(False)\n",
        "        else:\n",
        "            spaces.append(True)\n",
        "\n",
        "    doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
        "    x.append(sent2features(doc))\n",
        "    y.append(pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TxXxO5uErf7F"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train: List[Dict[str, Union[str, bool]]] = []\n",
        "x_test: List[Dict[str, Union[str, bool]]] = []\n",
        "y_train: List[str] = []\n",
        "y_test: List[str] = []\n",
        "\n",
        "x_train, x_test = train_test_split(x, test_size=0.2, shuffle=True, random_state=42)\n",
        "y_train, y_test = train_test_split(y, test_size=0.2, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwC9gGuqzis3"
      },
      "source": [
        "## Training the POS tagging model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUVzink6MKPu"
      },
      "source": [
        "import the sklearn-crfsuite package.\n",
        "\n",
        "if you see **AttributeError: 'CRF' object has no attribute 'keep_tempfiles'** error, then downgrade your **sklearn** module under 0.24\n",
        "\n",
        "!pip install -U 'scikit-learn<0.24'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJMeI76O2TSh",
        "outputId": "c6247fc1-3716-47cf-e29b-97fbfefe72ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6\n",
            "Requirement already satisfied: scikit-learn<0.24 in /usr/local/lib/python3.7/dist-packages (0.23.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "# If the sklearn_crfsuite package is not intalled\n",
        "# uncomment the following line:\n",
        "!pip install sklearn-crfsuite\n",
        "!pip install -U 'scikit-learn<0.24'\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E1mPrtHP985",
        "outputId": "8344a557-c8f8-47e0-e664-70d88b203cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='ap', keep_tempfiles=None, max_iterations=100)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='ap',\n",
        "    max_iterations=100\n",
        "    )\n",
        "\n",
        "crf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nq88MH73807"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iETlPdFUQhfN",
        "outputId": "29d1130e-b294-4698-bc62-38751959ee6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9774584244180281\n",
            "0.6827694454133241\n"
          ]
        }
      ],
      "source": [
        "y_pred = crf.predict(x_test)\n",
        "\n",
        "print(metrics.flat_accuracy_score(y_test, y_pred))\n",
        "print(metrics.sequence_accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCCO_mAjRViP"
      },
      "source": [
        "## L-BFGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouOs1JPfMKPv",
        "outputId": "b7131a2d-72a7-41f9-aaf5-c5d10193103e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
              "    keep_tempfiles=None, max_iterations=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "crf2 = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=1000,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "\n",
        "crf2.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP6uZZaK3qQu",
        "outputId": "d24483ea-6499-46e2-cc66-5797edebd6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9774584244180281\n",
            "0.9773079833210477\n"
          ]
        }
      ],
      "source": [
        "y_pred = crf.predict(x_test)\n",
        "\n",
        "print(metrics.flat_accuracy_score(y_test, y_pred))\n",
        "print(metrics.flat_f1_score(y_test, y_pred, average=\"weighted\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "pos_tagging.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d1e8c0d757e42bb6dd2d02df6dd6ac3621d4ac94b1d7e71b9ccf65bd0d184b20"
    },
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}